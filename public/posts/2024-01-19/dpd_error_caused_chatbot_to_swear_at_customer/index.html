<!doctype html><html lang=en-us><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><style type=text/css>body{font-family:monospace}</style><title>DPD error caused chatbot to swear at customer</title>
<link rel=stylesheet href=/css/style.css></head><body><header>==============================<br>== <a href=http://localhost:1313/>#Probllama by OpenShield</a> ==<br>==============================<div style=float:right></div><br><p><nav><a href=/><b>Home</b></a>.
<a href=/index.xml><b>RSS</b></a>.</nav></p></header><main><article><h1>DPD error caused chatbot to swear at customer</h1><b><time>2024-01-19 00:00:00</time></b><div><p>DPD has disabled part of its online support chatbot after it swore at a customer. The parcel delivery firm uses artificial intelligence (AI) in its online chat to answer queries, in addition to human operators. A new update caused it to behave unexpectedly, including swearing and criticizing the company.</p><p>DPD said it had disabled the part of the chatbot that was responsible and was updating its system as a result. &ldquo;An error occurred after a system update yesterday. The AI element was immediately disabled and is currently being updated,&rdquo; the firm said in a statement.</p><p>Before the change could be made, word of the mix-up spread across social media after being spotted by a customer. One particular post was viewed 800,000 times in 24 hours, as people gleefully shared the latest botched attempt by a company to incorporate AI into its business. The chatbot was easily convinced to swear at the customer and criticize DPD, even writing a haiku about the company&rsquo;s poor performance.</p><p>Many modern chatbots use large language models, such as that popularized by ChatGPT. While they can simulate real conversations with people, they can often be convinced to say things they weren&rsquo;t designed to say. This incident follows similar issues with chatbots, including one where a car dealership&rsquo;s chatbot agreed to sell a Chevrolet for a single dollar.</p><p><a href=https://www.bbc.com/news/technology-68025677>More details here</a></p></div></article></main><aside><div><div><h3>LATEST POSTS</h3></div><div><ul><li><a href=/posts/2024-07-25/google_colab_ai_data_leakage_through_image_rendering_fixed_some_risks_remain.md/>Google Colab AI: Data Leakage Through Image Rendering Fixed. Some Risks Remain.</a></li><li><a href=/posts/2024-07-22/breaking_instruction_hierarchy_in_openais_gpt_4o_mini/>Breaking Instruction Hierarchy in OpenAI\'s gpt-4o-mini</a></li><li><a href=/posts/2024-07-08/sorry_chatgpt_is_under_maintenance_persistent_denial_of_service_through_prompt_injection_and_memory_attacks/>Sorry, ChatGPT Is Under Maintenance: Persistent Denial of Service through Prompt Injection and Memory Attacks</a></li><li><a href=/posts/2024-06-23/cve_2024_37032_ollama_remote_code_execution/>ðŸš¨ New CVE Alert: CVE-2024-37032 - Ollama Remote Code Execution ðŸš¨</a></li><li><a href=/posts/2024-06-14/github_copilot_chat_from_prompt_injection_to_data_exfiltration/>GitHub Copilot Chat: From Prompt Injection to Data Exfiltration</a></li></ul></div></div></aside><footer><p>&copy; 2024 <a href=http://localhost:1313/><b>#Probllama by OpenShield</b></a>.
<a href=https://github.com/openshieldai/probllama><b>Github</b></a>.
<a href=https://openshield.ai><b>OpenShield</b></a>.</p></footer></body></html>
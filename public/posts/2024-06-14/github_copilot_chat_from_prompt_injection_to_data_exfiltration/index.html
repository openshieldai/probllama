<!doctype html><html lang=en-us><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><style type=text/css>body{font-family:monospace}</style><title>GitHub Copilot Chat: From Prompt Injection to Data Exfiltration</title>
<link rel=stylesheet href=/css/style.css></head><body><header>==============================<br>== <a href=http://localhost:1313/>#Probllama by OpenShield</a> ==<br>==============================<div style=float:right></div><br><p><nav><a href=/><b>Home</b></a>.
<a href=/index.xml><b>RSS</b></a>.</nav></p></header><main><article><h1>GitHub Copilot Chat: From Prompt Injection to Data Exfiltration</h1><b><time>2024-06-14 21:00:17</time></b><div><p>This post highlights how the GitHub Copilot Chat VS Code Extension was vulnerable to data exfiltration via prompt injection when analyzing untrusted source code. GitHub Copilot Chat GitHub Copilot Chat is a VS Code Extension that allows a user to chat with source code, refactor code, get info about terminal output, or general help about VS Code, and things along those lines. It does so by sending source code, along with the userâ€™s questions to a large language model (LLM).
<a href=https://embracethered.com/blog/posts/2024/github-copilot-chat-prompt-injection-data-exfiltration/>More details here</a></p></div></article></main><aside><div><div><h3>LATEST POSTS</h3></div><div><ul><li><a href=/posts/2024-07-25/google_colab_ai_data_leakage_through_image_rendering_fixed_some_risks_remain.md/>Google Colab AI: Data Leakage Through Image Rendering Fixed. Some Risks Remain.</a></li><li><a href=/posts/2024-07-22/breaking_instruction_hierarchy_in_openais_gpt_4o_mini/>Breaking Instruction Hierarchy in OpenAI\'s gpt-4o-mini</a></li><li><a href=/posts/2024-07-08/sorry_chatgpt_is_under_maintenance_persistent_denial_of_service_through_prompt_injection_and_memory_attacks/>Sorry, ChatGPT Is Under Maintenance: Persistent Denial of Service through Prompt Injection and Memory Attacks</a></li><li><a href=/posts/2024-06-23/cve_2024_37032_ollama_remote_code_execution/>ðŸš¨ New CVE Alert: CVE-2024-37032 - Ollama Remote Code Execution ðŸš¨</a></li><li><a href=/posts/2024-06-14/github_copilot_chat_from_prompt_injection_to_data_exfiltration/>GitHub Copilot Chat: From Prompt Injection to Data Exfiltration</a></li></ul></div></div></aside><footer><p>&copy; 2024 <a href=http://localhost:1313/><b>#Probllama by OpenShield</b></a>.
<a href=https://github.com/openshieldai/probllama><b>Github</b></a>.
<a href=https://openshield.ai><b>OpenShield</b></a>.</p></footer></body></html>